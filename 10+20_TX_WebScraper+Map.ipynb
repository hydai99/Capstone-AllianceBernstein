{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get Source data for All _District Download_. web scraping\n",
    "\n",
    "year='2017'\n",
    "'https://rptsvr1.tea.texas.gov/perfreport/tapr/{}/xplore/DownloadSelData.html'.format(year)\n",
    "\n",
    "step1\n",
    "- 2021-22\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2022/xplore/DownloadSelData.html\n",
    "- 2020-21\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2021/xplore/DownloadSelData.html\n",
    "- 2018-19\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2019/xplore/DownloadSelData.html\n",
    "- 2017-18\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2018/xplore/DownloadSelData.html\n",
    "- 2016-17\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2017/xplore/DownloadSelData.html\n",
    "\n",
    "step2 (**web scraping start from here**)\n",
    "\n",
    "- 2021-22\thttps://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&prgopt=2022/xplore/setdists.sas&year4=2022&_program=perfrept.perfmast.sas&sumlev=D&steps=2\n",
    "- 2016-17\thttps://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&prgopt=2017/xplore/setdists.sas&year4=2017&_program=perfrept.perfmast.sas&sumlev=D&steps=2\n",
    "\n",
    "step3\n",
    "- https://rptsvr1.tea.texas.gov/cgi/sas/broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_service = Service('chromedriver_mac_arm64/chromedriver')   # edit based on the version of used web browser \n",
    "\n",
    "years=[2017,2018,2019,2021,2022]\n",
    "for year in years:\n",
    "    locals()[f'me_{year}'] = pd.DataFrame(columns=['year','metric','element'])\n",
    "\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    prefs = {'download.default_directory' :  os.getcwd()+'/TX_data/TAPR_District/{}'.format(year)}; \n",
    "    chrome_options.add_experimental_option('prefs', prefs)\n",
    "    #chrome_options.add_argument('--headless')   # uncomment if want to run in backend\n",
    "    driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "    # Go to the first website\n",
    "    driver.get(\"https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&prgopt={}/xplore/setdists.sas&year4={}&_program=perfrept.perfmast.sas&sumlev=D&steps=2\".format(year,year))\n",
    "\n",
    "    # Wait for the \"continue\" button to be clickable\n",
    "    continue_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//input[@value='Continue']\"))\n",
    "    )\n",
    "    continue_button.click()\n",
    "\n",
    "    # Select the select element with name \"dsname\"\n",
    "    dsname_select = Select(driver.find_element(by=By.NAME, value=\"dsname\"))\n",
    "\n",
    "    # Loop over all options\n",
    "    m=[]\n",
    "    for option in dsname_select.options:\n",
    "        dsname_select.select_by_value(option.get_attribute(\"value\"))\n",
    "        m.append(option.get_attribute(\"value\"))\n",
    "\n",
    "    for option in m:\n",
    "        option_element = driver.find_element(by=By.XPATH, value=f\"//option[@value='{option}']\")\n",
    "        option_element.click()\n",
    "        \n",
    "        # Wait for the \"continue\" button to be clickable\n",
    "        continue_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//input[@value='Continue']\"))\n",
    "        )\n",
    "        continue_button.click()\n",
    "        \n",
    "        # Choose excel format (There is no csv fomat from the first 3 years)\n",
    "        # option_csv=driver.find_element(by=By.XPATH,value=f\"//option[@value='X']\")  # xls format. \n",
    "        # option_csv.click()\n",
    "\n",
    "        # get all value of checkbox\n",
    "        checkboxes = driver.find_elements(by=By.XPATH, value=\"//input[@type='checkbox']\")\n",
    "\n",
    "        data_element=[]\n",
    "        for checkbox in checkboxes:\n",
    "            data_element.append(checkbox.get_attribute(\"value\"))\n",
    "        \n",
    "        # Wait for the \"select all\" button to be clickable\n",
    "        select_all_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//input[@value='Select All']\"))\n",
    "        )\n",
    "        select_all_button.click()\n",
    "        \n",
    "        # Wait for the \"download\" button to be clickable &  Download\n",
    "        download_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//input[@value='Download']\"))\n",
    "        )\n",
    "        download_button.click()\n",
    "\n",
    "        locals()[f'me_{year}'] = pd.concat([locals()[f'me_{year}'], pd.DataFrame({'year': year, 'metric': option, 'element': data_element})], ignore_index=True)\n",
    "        \n",
    "        driver.back()\n",
    "    \n",
    "    # Make sure all downaload have been finished\n",
    "    time.sleep(10) \n",
    "    driver.quit()\n",
    "    \n",
    "    locals()[f'me_{year}'] = locals()[f'me_{year}'].groupby(['year', 'metric'])['element'].apply(list).reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine file into 1 dataframe according to its year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(folder_path):\n",
    "    all_files = os.listdir(folder_path)\n",
    "    dataframes = []\n",
    "    for file in all_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file.endswith('.xls'):\n",
    "            df = pd.read_html(file_path)[0]\n",
    "        else:\n",
    "            print(file_path)\n",
    "            continue\n",
    "        dataframes.append(df)\n",
    "    return pd.concat(dataframes, axis=0)\n",
    "\n",
    "\n",
    "years=[2017,2018,2019,2021,2022]\n",
    "for year in years:\n",
    "    folder_path =  os.getcwd()+'/TX_data/TAPR_District/{}'.format(year)\n",
    "    merged_df = merge_files(folder_path)\n",
    "    merged_df.to_csv(os.path.join( os.getcwd(), f\"TX_data/TAPR_District/merged_{year}.csv\"), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get all metric & elements\n",
    "\n",
    "## 1) Get all metric\n",
    "'https://rptsvr1.tea.texas.gov/perfreport/tapr/{}/xplore/taprref.html'.format(year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=[2017,2018,2019,2021,2022]\n",
    "for year in years:\n",
    "    locals()[f'df_metric_{year}'] = pd.DataFrame(columns=['year','metric','meaning','href'])\n",
    "    metric_url='https://rptsvr1.tea.texas.gov/perfreport/tapr/{}/xplore/taprref.html'.format(year)\n",
    "    \n",
    "    response = requests.get(metric_url)\n",
    "    html = response.content\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    for tag in soup.find_all('p'):\n",
    "        try:\n",
    "            context = tag.text.strip()\n",
    "            if context.startswith('d'):\n",
    "                link = tag.find('a').get('href')\n",
    "                \n",
    "                if link.endswith('html'):\n",
    "                    link=metric_url.rstrip('taprref.html')+link\n",
    "                \n",
    "                metric=context.split('--')[0].strip()\n",
    "                meaning=tag.text.split('--')[1].strip()\n",
    "                \n",
    "                #locals()[f'df_metric_{year}'] = locals()[f'df_metric_{year}'].append({'year':year,'metric':metric,'meaning':meaning,'href': link}, ignore_index=True)\n",
    "                new_row = pd.DataFrame({'year':year,'metric':metric,'meaning':meaning,'href': link})\n",
    "                locals()[f'df_metric_{year}'] = pd.concat([locals()[f'df_metric_{year}'], new_row], ignore_index=True)\n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if they have same metric among 5 different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>meaning</th>\n",
       "      <th>occurrence_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dadv</td>\n",
       "      <td>Advanced/Dual-Credit Course Completion (Grades...</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dapib</td>\n",
       "      <td>AP/IB Results</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbil1</td>\n",
       "      <td>BE/ESL: Approaches Grade Level, Meets Grade Le...</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbil2</td>\n",
       "      <td>BE/ESL Academic Growth: All Grades ELA/Reading...</td>\n",
       "      <td>[2017, 2018, 2019, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>dstaar_ssi8</td>\n",
       "      <td>Student Success Initiative (Grade 8)</td>\n",
       "      <td>[2018, 2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>dstaf</td>\n",
       "      <td>Staff Information</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dstud</td>\n",
       "      <td>Student Information</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>dtxihe</td>\n",
       "      <td>Texas Institution of Higher Education (TX IHE)...</td>\n",
       "      <td>[2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         metric                                            meaning  \\\n",
       "0          dadv  Advanced/Dual-Credit Course Completion (Grades...   \n",
       "1         dapib                                      AP/IB Results   \n",
       "2         dbil1  BE/ESL: Approaches Grade Level, Meets Grade Le...   \n",
       "3         dbil2  BE/ESL Academic Growth: All Grades ELA/Reading...   \n",
       "..          ...                                                ...   \n",
       "52  dstaar_ssi8               Student Success Initiative (Grade 8)   \n",
       "53        dstaf                                  Staff Information   \n",
       "54        dstud                                Student Information   \n",
       "55       dtxihe  Texas Institution of Higher Education (TX IHE)...   \n",
       "\n",
       "                   occurrence_year  \n",
       "0   [2017, 2018, 2019, 2021, 2022]  \n",
       "1   [2017, 2018, 2019, 2021, 2022]  \n",
       "2   [2017, 2018, 2019, 2021, 2022]  \n",
       "3         [2017, 2018, 2019, 2022]  \n",
       "..                             ...  \n",
       "52                    [2018, 2019]  \n",
       "53  [2017, 2018, 2019, 2021, 2022]  \n",
       "54  [2017, 2018, 2019, 2021, 2022]  \n",
       "55        [2018, 2019, 2021, 2022]  \n",
       "\n",
       "[56 rows x 3 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = pd.concat([df_metric_2017,df_metric_2018,df_metric_2019,df_metric_2021,df_metric_2022])\n",
    "\n",
    "# create a new column 'first_meaning' containing the first value of the 'meaning' column for each 'metric'\n",
    "first_meanings = df_concat.groupby('metric').last()['meaning'].reset_index()\n",
    "\n",
    "# join 'first_meaning'\n",
    "metric_year = df_concat[['metric', 'year']].merge(first_meanings, on='metric', how='left')\n",
    "\n",
    "# groupby 'metric' and aggregate 'year' into a list\n",
    "metric_year= metric_year.groupby(['metric', 'meaning']).agg({'year': lambda x: x.tolist()})\n",
    "\n",
    "# reset index and rename the columns\n",
    "metric_year = metric_year.reset_index()\n",
    "metric_year['metric']=metric_year['metric'].str.lower()\n",
    "metric_year.rename(columns={'year': 'occurrence_year'}, inplace=True)\n",
    "metric_year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Get all dataelement inside each metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame(columns=['metric','elements'])\n",
    "for index, row in metric_year.iterrows():\n",
    "    metric = row['metric']\n",
    "    years = row['occurrence_year']\n",
    "    \n",
    "    data_elements=[]\n",
    "    for year in years:\n",
    "        element_url='https://rptsvr1.tea.texas.gov/perfreport/tapr/{}/xplore/{}.html'.format(year,metric)\n",
    "        html_content = requests.get(element_url)\n",
    "        soup = bs(html_content.text, 'html.parser')\n",
    "\n",
    "        # Find the table element in the HTML\n",
    "        table = soup.find('table')\n",
    "        for td in table.find_all('td')[::4]:\n",
    "            element = td.text.strip()\n",
    "            data_elements.append(element)\n",
    "    data_elements=list(set(data_elements))\n",
    "        \n",
    "    new_row = pd.DataFrame({'metric': [metric], 'elements': [data_elements]})\n",
    "    df3 = pd.concat([df3, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>elements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dadv</td>\n",
       "      <td>[DL9ADS18R, DR0ADE15R, DE9ADC18R, DH9ADE19R, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dapib</td>\n",
       "      <td>[DH0BTE18R, D20BTA15R, D20BKC15R, DA0BKA21R, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbil1</td>\n",
       "      <td>[DDT00AS01S18R, DD500A001218R, DDJ00AR01319R, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbil2</td>\n",
       "      <td>[DDA00AR01217R, DDT00AS01S18R, DQ00AM03A17R, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dbil3</td>\n",
       "      <td>[DJ408FR18R, DX00AR02G16R, DL00AR02E16R, DX00A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric                                           elements\n",
       "0   dadv  [DL9ADS18R, DR0ADE15R, DE9ADC18R, DH9ADE19R, D...\n",
       "1  dapib  [DH0BTE18R, D20BTA15R, D20BKC15R, DA0BKA21R, D...\n",
       "2  dbil1  [DDT00AS01S18R, DD500A001218R, DDJ00AR01319R, ...\n",
       "3  dbil2  [DDA00AR01217R, DDT00AS01S18R, DQ00AM03A17R, D...\n",
       "4  dbil3  [DJ408FR18R, DX00AR02G16R, DL00AR02E16R, DX00A..."
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and rename variable above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=[2017,2018,2019,2021,2022]\n",
    "\n",
    "# Combine each year - metric -element.\n",
    "for year in years:\n",
    "    locals()[f'df_me_{year}'] = pd.merge(locals()[f'df_metric_{year}'],locals()[f'me_{year}']  , on=['year','metric'])\n",
    "\n",
    "# Combine above\n",
    "df_me=pd.merge(df3, metric_year,on='metric')\n",
    "\n",
    "# Convert to upper case\n",
    "def convert_column_to_uppercase(df, column_name):\n",
    "    df[column_name] = df[column_name].str.upper()\n",
    "    return df\n",
    "\n",
    "df_list = [df_metric_2017,df_metric_2018,df_metric_2019,df_metric_2021,df_metric_2022,df_me]\n",
    "for f in df_list:\n",
    "    f = convert_column_to_uppercase(f, 'metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>elements</th>\n",
       "      <th>meaning</th>\n",
       "      <th>occurrence_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DADV</td>\n",
       "      <td>[DL9ADS18R, DR0ADE15R, DE9ADC18R, DH9ADE19R, D...</td>\n",
       "      <td>Advanced/Dual-Credit Course Completion (Grades...</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAPIB</td>\n",
       "      <td>[DH0BTE18R, D20BTA15R, D20BKC15R, DA0BKA21R, D...</td>\n",
       "      <td>AP/IB Results</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DBIL1</td>\n",
       "      <td>[DDT00AS01S18R, DD500A001218R, DDJ00AR01319R, ...</td>\n",
       "      <td>BE/ESL: Approaches Grade Level, Meets Grade Le...</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DBIL2</td>\n",
       "      <td>[DDA00AR01217R, DDT00AS01S18R, DQ00AM03A17R, D...</td>\n",
       "      <td>BE/ESL Academic Growth: All Grades ELA/Reading...</td>\n",
       "      <td>[2017, 2018, 2019, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DSTAAR_SSI8</td>\n",
       "      <td>[DR8GPPR18R, DR08AMAP519R, DL08AMAF518R, DM8GP...</td>\n",
       "      <td>Student Success Initiative (Grade 8)</td>\n",
       "      <td>[2018, 2019]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DSTAF</td>\n",
       "      <td>[DPSOTOFC, DPSTVOFC, DPSTBIFC, DPSTSPFC, DPSTT...</td>\n",
       "      <td>Staff Information</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DSTUD</td>\n",
       "      <td>[DE0GR16N, DPEMPCIP, DPETSPHP, DPEMWHIP, DPEMH...</td>\n",
       "      <td>Student Information</td>\n",
       "      <td>[2017, 2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>DTXIHE</td>\n",
       "      <td>[DHHEE20R, DW0GV19R, DAHEE20R, DWHEC19R, D40GV...</td>\n",
       "      <td>Texas Institution of Higher Education (TX IHE)...</td>\n",
       "      <td>[2018, 2019, 2021, 2022]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         metric                                           elements  \\\n",
       "0          DADV  [DL9ADS18R, DR0ADE15R, DE9ADC18R, DH9ADE19R, D...   \n",
       "1         DAPIB  [DH0BTE18R, D20BTA15R, D20BKC15R, DA0BKA21R, D...   \n",
       "2         DBIL1  [DDT00AS01S18R, DD500A001218R, DDJ00AR01319R, ...   \n",
       "3         DBIL2  [DDA00AR01217R, DDT00AS01S18R, DQ00AM03A17R, D...   \n",
       "..          ...                                                ...   \n",
       "52  DSTAAR_SSI8  [DR8GPPR18R, DR08AMAP519R, DL08AMAF518R, DM8GP...   \n",
       "53        DSTAF  [DPSOTOFC, DPSTVOFC, DPSTBIFC, DPSTSPFC, DPSTT...   \n",
       "54        DSTUD  [DE0GR16N, DPEMPCIP, DPETSPHP, DPEMWHIP, DPEMH...   \n",
       "55       DTXIHE  [DHHEE20R, DW0GV19R, DAHEE20R, DWHEC19R, D40GV...   \n",
       "\n",
       "                                              meaning  \\\n",
       "0   Advanced/Dual-Credit Course Completion (Grades...   \n",
       "1                                       AP/IB Results   \n",
       "2   BE/ESL: Approaches Grade Level, Meets Grade Le...   \n",
       "3   BE/ESL Academic Growth: All Grades ELA/Reading...   \n",
       "..                                                ...   \n",
       "52               Student Success Initiative (Grade 8)   \n",
       "53                                  Staff Information   \n",
       "54                                Student Information   \n",
       "55  Texas Institution of Higher Education (TX IHE)...   \n",
       "\n",
       "                   occurrence_year  \n",
       "0   [2017, 2018, 2019, 2021, 2022]  \n",
       "1   [2017, 2018, 2019, 2021, 2022]  \n",
       "2   [2017, 2018, 2019, 2021, 2022]  \n",
       "3         [2017, 2018, 2019, 2022]  \n",
       "..                             ...  \n",
       "52                    [2018, 2019]  \n",
       "53  [2017, 2018, 2019, 2021, 2022]  \n",
       "54  [2017, 2018, 2019, 2021, 2022]  \n",
       "55        [2018, 2019, 2021, 2022]  \n",
       "\n",
       "[56 rows x 4 columns]"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_me"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save above variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the variables to a file\n",
    "with open(\"TX_data/variables.pickle\", \"wb\") as f:\n",
    "    pickle.dump((me_2017,me_2018,me_2019,me_2021,me_2022,\n",
    "                 df_metric_2017,df_metric_2018,df_metric_2019,df_metric_2021,df_metric_2022,\n",
    "                 df_me_2017,df_me_2018,df_me_2019,df_me_2021,df_me_2022,\n",
    "                 metric_year,df3), f)  \n",
    "    \n",
    "    \n",
    "with open(\"TX_data/variables2.pickle\", \"wb\") as f:\n",
    "    pickle.dump((df_me),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the variables from the file\n",
    "# with open(\"TX_data/variables.pickle\", \"rb\") as f:\n",
    "#     me_2017,me_2018,me_2019,me_2021,me_2022,df_metric_2017,df_metric_2018,df_metric_2019,df_metric_2021,df_metric_2022,df_me_2017,df_me_2018,df_me_2019,df_me_2021,df_me_2022,metric_year,df3= pickle.load(f)\n",
    "\n",
    "# with open(\"TX_data/variables2.pickle\", \"rb\") as f:\n",
    "#     df_me = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PDF to table\n",
    "Link:\n",
    "- 2021-22\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2022/datadict.pdf\n",
    "- 2020-21\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2021/datadict.pdf\n",
    "- 2018-19\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2019/datadict.pdf\n",
    "- 2017-18\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2018/datadict.pdf\n",
    "- 2016-17\thttps://rptsvr1.tea.texas.gov/perfreport/tapr/2017/datadict.pdf\n",
    "\n",
    "Note: Above link also cover campus data. We only need to choose district table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://rptsvr1.tea.texas.gov/perfreport/tapr/2017/datadict.pdf\n",
      "https://rptsvr1.tea.texas.gov/perfreport/tapr/2018/datadict.pdf\n",
      "https://rptsvr1.tea.texas.gov/perfreport/tapr/2019/datadict.pdf\n",
      "https://rptsvr1.tea.texas.gov/perfreport/tapr/2021/datadict.pdf\n",
      "https://rptsvr1.tea.texas.gov/perfreport/tapr/2022/datadict.pdf\n"
     ]
    }
   ],
   "source": [
    "# Download datadict via its url\n",
    "from urllib.request import urlretrieve\n",
    "years=['2017','2018','2019','2021','2022']\n",
    "for year in years:\n",
    "    datadict_url='https://rptsvr1.tea.texas.gov/perfreport/tapr/{}/datadict.pdf'.format(year)\n",
    "    urlretrieve(datadict_url, 'datadict/datadict_'+year+'.pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract table from pdf via Azure Form Recognizer\n",
    "manually delete 'campus' part. Only leave district part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import PyPDF2\n",
    "import io\n",
    "\n",
    "endpoint_pay='input_your_endpoint'\n",
    "key_pay='input_your_key'\n",
    "\n",
    "def datadict_csv_pay(endpoint,key):\n",
    "\n",
    "    in_path = \"TX_data/datadict/district/\"\n",
    "    allfiles = os.listdir(in_path)\n",
    "    files = [ fname for fname in allfiles if fname.endswith('.pdf')]\n",
    "\n",
    "    for filename in files:\n",
    "\n",
    "        document_analysis_client = DocumentAnalysisClient(\n",
    "            endpoint=endpoint_pay, credential=AzureKeyCredential(key_pay)\n",
    "        )\n",
    "        with open(in_path+filename, \"rb\") as f:\n",
    "            poller = document_analysis_client.begin_analyze_document(\n",
    "                \"prebuilt-layout\", document=f\n",
    "            )\n",
    "        result = poller.result()\n",
    "\n",
    "        tables = []\n",
    "        output=pd.DataFrame()\n",
    "        for table_idx, table in enumerate(result.tables):\n",
    "            df = [['' for i in range(table.column_count)] for j in range(table.row_count)] \n",
    "\n",
    "            for cell in table.cells:\n",
    "                df[cell.row_index][cell.column_index] = cell.content         \n",
    "\n",
    "            df=pd.DataFrame(df)\n",
    "            output=pd.concat([output,df],axis=0,ignore_index=True)\n",
    "            empty_row = pd.DataFrame({col: [None] for col in output.columns})\n",
    "            output=pd.concat([output,empty_row],axis=0,ignore_index=True)\n",
    "            \n",
    "        output.to_csv(in_path+filename[:-4]+'.csv',header=False,index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use free key.\n",
    "def datadict_csv(endpoint,key):\n",
    "    in_path = \"TX_data/datadict/district/\"\n",
    "    allfiles = os.listdir(in_path)\n",
    "    files = [ fname for fname in allfiles if fname.endswith('.pdf')]\n",
    "\n",
    "    for filename in files:\n",
    "        \n",
    "        # Open the PDF\n",
    "        with open(in_path+filename, 'rb') as file:\n",
    "            pdf = PyPDF2.PdfFileReader(file)\n",
    "            \n",
    "            # Get the number of pages\n",
    "            num_pages = pdf.getNumPages()\n",
    "            \n",
    "            # Divide the number of pages by 2 to get the number of output PDFs\n",
    "            num_output_pdfs = num_pages // 2\n",
    "            \n",
    "            # Loop over the output PDFs\n",
    "            output=pd.DataFrame()\n",
    "            for i in range(num_output_pdfs):\n",
    "                # Create a new PDF\n",
    "                output_pdf = PyPDF2.PdfFileWriter()\n",
    "                \n",
    "                # Add the first 2 pages to the new PDF\n",
    "                output_pdf.addPage(pdf.getPage(i * 2))\n",
    "                output_pdf.addPage(pdf.getPage(i * 2 + 1))\n",
    "                \n",
    "                document_analysis_client = DocumentAnalysisClient(\n",
    "                    endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "                )\n",
    "\n",
    "                with io.BytesIO() as f:\n",
    "                    output_pdf.write(f)\n",
    "                    f.seek(0)\n",
    "                    poller = document_analysis_client.begin_analyze_document(\n",
    "                    \"prebuilt-layout\", document=f.read()\n",
    "                        )\n",
    "                    \n",
    "                result = poller.result()\n",
    "\n",
    "                tables = []\n",
    "                \n",
    "                for table_idx, table in enumerate(result.tables):\n",
    "\n",
    "                    print(\"Table # {} has {} rows and {} columns; Table Page # is {}\".format(table_idx, table.row_count, table.column_count,table.bounding_regions[0].page_number))    \n",
    "\n",
    "                    df = [['' for i in range(table.column_count)] for j in range(table.row_count)] \n",
    "                    for cell in table.cells:\n",
    "                        df[cell.row_index][cell.column_index] = cell.content         \n",
    "\n",
    "                    df=pd.DataFrame(df)\n",
    "                    output=pd.concat([output,df],axis=0,ignore_index=True)\n",
    "                    empty_row = pd.DataFrame({col: [None] for col in output.columns})\n",
    "                    output=pd.concat([output,empty_row],axis=0,ignore_index=True)\n",
    "                \n",
    "            output.to_csv(in_path+filename[:-4]+'.csv',header=False,index=False)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Datadict process.\n",
    "process datadict file from 2017-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datadict_process(df2):\n",
    "\n",
    "    empty_rows = df2.loc[df2.iloc[:,1:].isna().all(axis=1)].index.tolist()\n",
    "    df2 = df2.applymap(str)\n",
    "    df2 = df2.replace('\\n:unselected:','', regex=True)\n",
    "    df2 = df2.replace(':unselected:', '', regex=True)\n",
    "    df2 = df2.replace('nan', '', regex=True)\n",
    "\n",
    "    # use ffill (forward fill) to fill empty strings in new column with values from first column\n",
    "    df2.insert(0, 'Data field', '')\n",
    "    for i in range(len(empty_rows)-1):\n",
    "        start_index = empty_rows[i]\n",
    "        end_index = empty_rows[i+1]\n",
    "        df2.iloc[start_index:end_index, 0] = df2.iloc[start_index, 1]\n",
    "\n",
    "    df2=df2.rename(columns={'Unnamed: 0':'Subcategory'})\n",
    "    df2.loc[:,'Subcategory'] = df2.loc[:,'Subcategory'].replace('', method='ffill')\n",
    "\n",
    "    return df2\n",
    "\n",
    "input_path =  os.getcwd()+'/TX_data/datadict/district/'\n",
    "output_path =  os.getcwd()+'/TX_data/datadict/district_processed/'\n",
    "csv_files = [os.path.join(input_path, f) for f in os.listdir(input_path) if f.endswith(\".csv\") and f.startswith('datadict')]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = datadict_process(df)\n",
    "    \n",
    "    base_name = os.path.splitext(csv_file)[0].replace(input_path,'')\n",
    "    new_name = base_name+ \".csv\"  #  + suffix \n",
    "    df.to_csv(output_path + new_name, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Table Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TX_data/variables2.pickle\", \"rb\") as f:\n",
    "    df_me = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Organize the meanings of abbreviations\n",
    "\"\"\"\n",
    "\n",
    "# abb=pd.read_csv('TX_data/abbreviations_explanation.csv')\n",
    "# df_split = abb['meaning'].str.split('(', expand=True)\n",
    "# abb['meaning']=df_split[0]\n",
    "# abb['abbr'] = abb['abbr'].combine_first(df_split[1].str.replace(')', '') )\n",
    "# abb.to_csv('TX_data/abbreviations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input one element, \n",
    "it will find all releated element in the past five years\n",
    "return a dataframe with all metric and its district\n",
    "\n",
    "Note: State and Region ## column not applicate.\n",
    "\"\"\"\n",
    "\n",
    "abb=pd.read_csv('TX_data/abbreviations.csv')\n",
    "\n",
    "def get_row_number(input, df):\n",
    "    row_numbers = []\n",
    "    for i, row in df.iterrows():\n",
    "        if row['position_index']=='0':\n",
    "             if input[0] == row['abbr']:\n",
    "                row_numbers.append(i)\n",
    "        elif row['position_index']=='1':\n",
    "            if input[1] == row['abbr']:\n",
    "                row_numbers.append(i)\n",
    "        else:\n",
    "            if input[1:3] == row['abbr']:\n",
    "                row_numbers.append(i)        \n",
    "    return df.iloc[row_numbers,2:]\n",
    "    #get_row_number(input, abb)\n",
    "\n",
    "def select_columns(df, columns):\n",
    "    existing_columns = set(df.columns)\n",
    "    selected_columns = [col for col in columns if col in existing_columns]\n",
    "    return df[selected_columns]\n",
    "\n",
    "def mapping5(enum):\n",
    "    try:\n",
    "        position = df_me[df_me['elements'].apply(lambda x: enum in x)].index.tolist()[0]\n",
    "        e_years=df_me.loc[position,'occurrence_year']\n",
    "        e_metric=df_me.loc[position,'metric']\n",
    "        meaning=df_me.loc[position,'meaning']\n",
    "        print(enum,' belongs to metric: ',e_metric) \n",
    "        print('Occurrence year: ', e_years,)\n",
    "        print(\"Meaning: \",meaning)\n",
    "        \n",
    "        display(get_row_number(enum, abb))\n",
    "\n",
    "        ae=[]\n",
    "        for ind,i in enumerate(e_years):\n",
    "            ae.append(enum[:-3] + str(i)[2:4] + enum[-1])\n",
    "            ae.append(enum[:-3] + str(i-1)[2:4] + enum[-1])\n",
    "            ae.append(enum[:-3] + str(i-2)[2:4] + enum[-1])\n",
    "        ae=list(set(ae))\n",
    "        ae.sort()\n",
    "        ae.insert(0,'DISTRICT')\n",
    "\n",
    "        for ind,i in enumerate(e_years):\n",
    "            \n",
    "            if i<=2019:\n",
    "                df = pd.read_html(os.path.join('TAPR_District',str(i), e_metric+'.xls'))[0]\n",
    "            else:\n",
    "                df = pd.read_csv(os.path.join('TAPR_District',str(i), e_metric+'.csv'))\n",
    "            \n",
    "            dc= select_columns(df, ae)\n",
    "            \n",
    "            if ind==0:\n",
    "                doutput=dc\n",
    "            else:\n",
    "                doutput=pd.merge(doutput,dc,on='DISTRICT',how='outer')\n",
    "        \n",
    "        doutput=doutput.T.drop_duplicates().T\n",
    "        return doutput\n",
    "    \n",
    "    except:\n",
    "        print('please make sure ', enum,' not belong to State and Region ## column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DH00AS03A17R  belongs to metric:  DSTAAR6\n",
      "Occurrence year:  [2017]\n",
      "Meaning:  District STAAR Data - Masters Grade Level (All Grades)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position_index</th>\n",
       "      <th>meaning</th>\n",
       "      <th>abbr</th>\n",
       "      <th>type1</th>\n",
       "      <th>type2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>district</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>H</td>\n",
       "      <td>Student Groups Available for Postsecondary, At...</td>\n",
       "      <td>Student Groups</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   position_index     meaning abbr  \\\n",
       "2               0    district    D   \n",
       "39              1   Hispanic     H   \n",
       "\n",
       "                                                type1           type2  \n",
       "2                                                 NaN             NaN  \n",
       "39  Student Groups Available for Postsecondary, At...  Student Groups  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>DH00AS03A16R</th>\n",
       "      <th>DH00AS03A17R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'001902</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'001903</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'001904</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'001906</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'001907</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>'252902</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>'252903</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>'253901</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>'254901</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>'254902</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DISTRICT DH00AS03A16R DH00AS03A17R\n",
       "0     '001902           -1           -1\n",
       "1     '001903           -1           -1\n",
       "2     '001904           -1           -1\n",
       "3     '001906           -1           -1\n",
       "4     '001907            8           15\n",
       "...       ...          ...          ...\n",
       "1198  '252902           -1           -1\n",
       "1199  '252903           -1           -1\n",
       "1200  '253901            6            7\n",
       "1201  '254901            5           11\n",
       "1202  '254902           -1           11\n",
       "\n",
       "[1203 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df41=mapping5('DH00AS03A17R') \n",
    "df41"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input a list of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input element list\n",
    "it will find all releated elements in the past five years and meaning of each element\n",
    "return a dataframe with all metric and its district\n",
    "\"\"\"\n",
    "\n",
    "def mapping5_list(enum_list):\n",
    "    path_list=[]\n",
    "    ae=[] \n",
    "    for enum in enum_list:\n",
    "        try:\n",
    "            position = df_me[df_me['elements'].apply(lambda x: enum in x)].index.tolist()[0]\n",
    "        except:\n",
    "            print('please make sure ', enum,' not belong to State and Region ## column')\n",
    "            continue\n",
    "            \n",
    "        e_years=df_me.loc[position,'occurrence_year']\n",
    "        e_metric=df_me.loc[position,'metric']\n",
    "        print('occurrence_year: ', e_years)\n",
    "        print('metric: ',e_metric)\n",
    "\n",
    "        for ind,i in enumerate(e_years):\n",
    "            ae.append(enum[:-3] + str(i)[2:4] + enum[-1])\n",
    "            ae.append(enum[:-3] + str(i-1)[2:4] + enum[-1])\n",
    "            ae.append(enum[:-3] + str(i-2)[2:4] + enum[-1])\n",
    "            path_list.append(os.path.join('TAPR_District',str(i), e_metric))\n",
    "            \n",
    "    ae=list(set(ae))\n",
    "    ae.sort()\n",
    "    ae.insert(0,'DISTRICT')\n",
    "    path_list=list(set(path_list))\n",
    "    path_list.sort()\n",
    "        \n",
    "    for ind,path in enumerate(path_list):\n",
    "        print(path)\n",
    "        if int(path.split('/')[1])<=2019:\n",
    "            df = pd.read_html(path+'.xls')[0]\n",
    "        else:\n",
    "            df = pd.read_csv(path+'.csv')\n",
    "        dc= select_columns(df, ae)\n",
    "        \n",
    "        if ind==0:\n",
    "            output=dc\n",
    "        else:\n",
    "            output=pd.merge(output,dc,on='DISTRICT',how='outer')\n",
    "    \n",
    "    # Deal with duplicate columns. Save the one occur in later year.\n",
    "    output = output[output.columns[~output.columns.str.endswith('_x')]]\n",
    "    output=output.rename(columns={col: col.rstrip('_y') for col in output.columns if col.endswith('_y')})\n",
    "    output.sort_index(axis=1, ascending=False, inplace=True)\n",
    "    \n",
    "    # Sort columns by its name\n",
    "    cols = output.columns.tolist()\n",
    "    cols.sort()\n",
    "    cols.remove('DISTRICT')\n",
    "    cols.insert(0, 'DISTRICT')\n",
    "    output = output[cols]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occurrence_year:  [2018, 2019, 2021, 2022]\n",
      "metric:  DSTAAR_GR3\n",
      "occurrence_year:  [2018, 2019, 2021, 2022]\n",
      "metric:  DSTAAR_GR3\n",
      "occurrence_year:  [2018, 2019, 2021, 2022]\n",
      "metric:  DGRAD\n",
      "TAPR_District/2018/DGRAD\n",
      "TAPR_District/2018/DSTAAR_GR3\n",
      "TAPR_District/2019/DGRAD\n",
      "TAPR_District/2019/DSTAAR_GR3\n",
      "TAPR_District/2021/DGRAD\n",
      "TAPR_District/2021/DSTAAR_GR3\n",
      "TAPR_District/2022/DGRAD\n",
      "TAPR_District/2022/DSTAAR_GR3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>DB0GR17N</th>\n",
       "      <th>DB0GR18N</th>\n",
       "      <th>DB0GR20N</th>\n",
       "      <th>DB0GR21N</th>\n",
       "      <th>DDA03ARE1217R</th>\n",
       "      <th>DDA03ARE1218R</th>\n",
       "      <th>DDA03ARE1219R</th>\n",
       "      <th>DDA03ARE1221R</th>\n",
       "      <th>DDA03ARE1222R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'001902</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'001903</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'001904</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'001906</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>'015842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>'015843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>'101877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>'152504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1218 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DISTRICT DB0GR17N DB0GR18N DB0GR20N DB0GR21N DDA03ARE1217R DDA03ARE1218R  \\\n",
       "0     '001902        3        1        2        2            42            57   \n",
       "1     '001903        6        2        6        5            50            55   \n",
       "2     '001904        5        5        2        3            42            54   \n",
       "3     '001906        1        3        3        1            57            55   \n",
       "...       ...      ...      ...      ...      ...           ...           ...   \n",
       "1214  '015842      NaN      NaN      NaN        .           NaN           NaN   \n",
       "1215  '015843      NaN      NaN      NaN        .           NaN           NaN   \n",
       "1216  '101877      NaN      NaN      NaN        .           NaN           NaN   \n",
       "1217  '152504      NaN      NaN      NaN        .           NaN           NaN   \n",
       "\n",
       "     DDA03ARE1219R DDA03ARE1221R DDA03ARE1222R  \n",
       "0               61            71            74  \n",
       "1               35            55            58  \n",
       "2               43            59            53  \n",
       "3               30            61            65  \n",
       "...            ...           ...           ...  \n",
       "1214           NaN           NaN             .  \n",
       "1215           NaN           NaN             .  \n",
       "1216           NaN           NaN             .  \n",
       "1217           NaN           NaN            71  \n",
       "\n",
       "[1218 rows x 10 columns]"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enum_list= ['DDA03ARE1219R','DDA03ARE1218R','DB0GR18N']\n",
    "d42=mapping5_list(enum_list)\n",
    "d42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab8f8ae80fafc6ac129e7fe646a0be18ed2869456ff4c93941a37a28edfebd3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
